<?xml version="1.0" encoding="UTF-8"?>
<section xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" version="5.0" xml:id="section_swift-partitioning">
    <title>Partitioning and File System Considerations</title>
    <para>
        After volumes are created and mapped to Swift nodes, they need to be partitioned and have a file system created on them. For each LUN that was created on the E-Series storage array create a single, new primary partition that utilizes the entire capacity available on the LUN.
    </para>
    <para>
        NetApp recommends the use of <command>dm-multipath</command> to provide support for redundant paths between an object storage node and the E-Series storage controller. For details on how to configure <command>dm-multipath</command>, refer to the link provided in XREF TO APPENDIX FIX ME.
    </para>
    <para>
        Swift currently requires that the underlying filesystem have support for extended attributes of the file system. While this requirement may be removed in a future release of Swift, as of the Havana release XFS is currently the recommended filesystem.
    </para>
    <para>
        Internal volumes created in a DDP layout resemble a traditional RAID 6 volume with the following parameters:
    </para>
    <itemizedlist>
        <listitem>Configuration: 8+2 RAID 6</listitem>
        <listitem>Segment Size:  128K</listitem>
        <listitem>Stripe Width:  1MB <inlineequation><mathphrase>(total number of data drives * segment size = 128K * 8)</mathphrase></inlineequation></listitem>
    </itemizedlist>
    <para>
        These parameters can be leveraged to configure the file system for optimal performance with the LUN. When a file system is created on a logical volume device, <command>mkfs.xfs</command> will automatically query the logical volume to determine appropriate stripe unit and stripe width values, unless values are passed at the time of filesystem creation; for example:
    </para>
    <programlisting>
mkfs.xfs –I su=131072,sw=8 –i size=1024 /dev/mapper/nodeX
    </programlisting>
    <para>
        You can verify that the underlying filesystem has the correct values for stripe unit and stripe width by using the <command>xfs_info</command> command:
    </para>
    <programlisting>
mroot@swift21:~/bin# xfs_info /dev/mapper/nodeX
meta-data=/dev/mapper/nodeX   isize=1024   agcount=4, agsize=134217664
blks     =                  sectsz=512   attr=2, projid32bit=0
data     =                  bsize=4096   blocks=536870655, imaxpct=5
         =                  sunit=32     swidth=256 blks
naming   =version 2         bsize=4096   ascii-ci=0
log      =internal log      bsize=4096   blocks=262144, version=2
         =                  sectsz=512   sunit=32 blks, lazy-count=1
realtime =none              extsz=4096   blocks=0, rtextents=0
    </programlisting>
    <para>
        <literal>sunit</literal> and <literal>swidth</literal> are shown in <literal>bsize</literal> (block size) units in the <command>xfs_info</command> command output.
    </para>
    <programlisting>
stripe unit= 32 sunits * 4096 bsize (block size)= 131072 bytes = 128K
stripe width= 256 blocks * 4096 bsize = 1M = 128K * 8 drives
    </programlisting>
    <para>
        The sysctl <literal>fs.xfs.rotorstep</literal> can be used to change how many files are put into an XFS allocation group. Increasing the default number from 1 to 255 reduces seeks to multiple allocation groups. NetApp has observed improved performance in some cases by increasing this number. You can put the following line in <filename>/etc/sysctl.conf</filename> to ensure this change is affected on each boot of the system:
    </para>
    <programlisting>
fs.xfs.rotorstep = 255
    </programlisting>
    <para>
        When mounting the XFS filesystem that resides on the LUNs offered from the E-Series storage, be sure to use the following mount options:
    </para>
    <programlisting>
mount –t xfs –o “nobarrier,noatime,nodiratime,logbugs=8,inode64” \
/dev/mapper/nodeX /srv/node/sdb1
    </programlisting>
</section>
